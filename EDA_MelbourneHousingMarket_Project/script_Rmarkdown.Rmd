---
always_allow_html: yes
leafletmap: true

output:
  html_document:
    keep_md: true

title: "Exploratory Data Analysis"
subtitle: 'Melbourne Housing Market'
date: 'Last update: `r format(Sys.time(), "%Y-%m-%d")`'
---

# Introducción

In this project for Mathematical Foundations of Data Analysis Course from the Big Data Master an Exploratory Data Analysis and Linear Regression Model is done using R and Melbourne Housing Market dataset.

This dataset can be downloaded from [this Kaggle website](https://www.kaggle.com/anthonypino/melbourne-housing-market):

The dataset includes data from houses sold in the real state market of Melbourne (Australia), price, address, suburb, number of rooms, real state agent...


## Preliminaries

+ Cleaning working directory and loading required libraries:

```{r}
rm(list = ls())
library(tidyverse)
library(leaflet)
library(corrplot)
library(GGally)
library(MLTools)
library(car)
library(caret)
```

+ The dataset is loaded and stored in the variable housing:

```{r}
housing <- read_csv('data/Melbourne_housing_FULL.csv')
```


# Analysis of the dataset

## Variable types

The original dataset consists on 34857 observations distributed in 21 variables.

The distribution of the variables is shown by the command summary: if it is numeric or categorical, between which values it moves, it mean...

```{r}
summary(housing)
```

Next, a description from each variable in the dataset is provided:

+ Suburb: Neighborhood where the house is located (categorical)
+ Address: Address of the house (categorical)
+ Rooms: Number of rooms of the house (discrete)
+ Type: house type (categorical)
      h - house, cottage, villa, semi, terrace 
      u - unit, duplex
      t - townhouse
+ Price: Price of the house in australian dollars (continuous)
+ Method: Sell method of the house (categorical)
      S - property sold 
      SP - property sold prior 
      PI - property passed in 
      PN - sold prior not disclosed 
      SN - sold not disclosed
      VB - vendor bid; 
      W - withdrawn prior to auction
      SA - sold after auction 
      SS - sold after auction price not disclosed 
+ SellerG: Real state agent (categorical)
+ Date: Sell date (categorical)
+ Distance: Distance to Central Business District of Melbourne (continuous)
+ Postcode: Postal code (categorical)
+ Bedroom2: Number of rooms, data scraped from another source (discrete)
+ Bathroom: Number of bathrooms (discrete)
+ Car: Number of car spots (discrete)
+ Landsize: Size of the terrain in meters (continuous)
+ Building Area: Building size in meters (continuous)
+ YearBuilt: Year the house was build (discrete)
+ CouncilArea: Governing council for the area (categorical)
+ Latitude: Latitude where the house is located (continuous)
+ Longitude: Longitude where the house is located (continuous)
+ Regionname: Region where the house is located (categorical)
+ Propertycount: Number of houses in the Neighborhood (discrete)


## Missing values treatment (NAs)

As it was seen with summary, there are a few registers with NAs values in some of their variables, 
Tal y como se vio en el summary existen bastantes registros con valores NAs en alguna de sus variables, they are going to be eliminated according to different criteria.

All the NAs observations from column Price are deleted.

```{r}
housing = housing %>% 
  drop_na(Price)
```

Now there is a total of 27247 observations, summary is executed to see the NAs distribution.

```{r}
summary(housing)
```

Decision to eliminate missing values in columns where there are little NA number is made. 

```{r}
housing = housing %>% 
  drop_na(Distance, Postcode, Propertycount)
```

Columns BuildingArea and Yearbuilt are deleted from the dataset because of the high percentage of NAs.

```{r}
housing$BuildingArea = NULL
housing$YearBuilt = NULL
```

It seems that the NAs observations in variables Car, Bathroom and Bedroom2 are the same (when an observation have one of these variables missing, have all of them). Additionally, variable Landsize have a high number of missing values.
Observations with NAs in previous mentioned variables are deleted from the dataset.

```{r}
housing = housing %>% 
  drop_na(Landsize, Car, Bathroom, Bedroom2)
```

Checking if there is anymore missing values in the dataset:

```{r}
apply(is.na(housing),2,which)
```

There are 22 observations with common NAs in Lattitude and Longitude, so they are eliminated.

```{r}
housing = housing %>% 
  drop_na(Lattitude, Longtitude)
```

It is verified that there are no longer any missing values in the table:

```{r}
any(is.na(housing))
```


## Study of variables

### Address variable

See how many unique values the Address variable has in case it could be divided in some way:

```{r}
length(unique(housing$Address))
```

Address granularity is very high, groups of this column will give too many results, so the column is eliminated because it won't provide useful information.

```{r}
housing$Address = NULL
```


### Suburb variable

This variable is converted to factor, showing how many levels it has and indicating in this way the number of suburbs within the houses are distributed.

```{r}
housing$Suburb = as.factor(housing$Suburb)
length(levels(housing$Suburb))
```


### Variable Rooms

Absolute frequency is showed for Rooms variable, indicating how many houses are for each number of rooms. The values are distributed between 1 and 12, focusing among 1 and 5.

```{r}
table(housing$Rooms)
```


### Variable Car

This variable indicates the number of car spots that a house have. The decision made is to transform it to factor and divide it into two levels: YES (if have car spot/s) or NO (don't have car spot/s).

```{r}
housing$Car = as.factor(housing$Car)
levels(housing$Car) = c("NO", "YES", "YES", "YES", "YES", "YES", "YES", "YES", "YES", "YES", "YES", "YES", "YES", "YES", "YES")
levels(housing$Car)
```


### Regionname variable

Regioname is transformed to factor and it levels are showed, observing 8 levels.

```{r}
housing$Regionname = as.factor(housing$Regionname)
levels(housing$Regionname)
```


### SellerG variable

This variable is going to be studied in detail in order to discover who are the sellers that get more houses sold and where are these houses located.

Firstly, the number of houses sold for each seller and the percentage with respect to the total is computed. The 5 sellers with more houses sold is showed.

```{r}
TopSellers = housing %>% 
  group_by(SellerG) %>% 
  dplyr::summarise(numberofhouses_sold = n()) %>% 
  mutate(percentageSold = round((numberofhouses_sold*100)/nrow(housing),2)) %>% 
  arrange(desc(percentageSold))
head(TopSellers, 5)
```

Nelson is the seller with more houses. Now, the number of houses sold by Nelson for each region and the probability of Nelson have sold a house in each one is computed.

```{r}
housing %>% 
  filter(SellerG == "Nelson") %>% 
  group_by(Regionname) %>% 
  dplyr::summarise(houses_by_nelson = n()) %>% 
  mutate(prob = round((houses_by_nelson / sum(houses_by_nelson)*100),2))
```

Next, a bar plot with the top 5 sellers is generated, showing how many where sold for each seller sorted from higher to lower value.

```{r}
sellerData = housing %>%
             group_by(SellerG) %>% 
             dplyr::summarise(CountPerSeller = n()) %>%
             arrange(desc(CountPerSeller))

sellerData = sellerData[0:5,]

ggplot(sellerData, aes(x = reorder(SellerG, CountPerSeller), 
                     y = CountPerSeller)) +
  geom_bar(stat='identity',colour="black", fill = '#f5a742') +
  geom_text(aes(x = SellerG, y = 1, label = paste0("(",CountPerSeller,")",sep="")),
            hjust=0, vjust=0.5, size = 4, colour = 'black',
            fontface = 'bold') +
  labs(x = 'Seller', y = 'Nº of houses', title = 'Top 5 sellers per nº of houses') +
  coord_flip()
```

Lastly, the houses sold by the top 5 sellers is plotted in a map (using leaflet library). Each point in the map is a house (located according to its values of Latitude and Longitude) and each color represents each one of the 5 sellers.

```{r}
Sellers = c(head(as.character(sellerData$SellerG),5))

SellersTop = housing %>% 
  filter(SellerG %in% Sellers)

center_lon = median(SellersTop$Longtitude)
center_lat = median(SellersTop$Lattitude)

pal <- colorFactor(
  palette = c('red', 'blue', 'green', 'purple', 'black'),
  domain = SellersTop$SellerG
)

leaflet(SellersTop) %>% addTiles() %>%
  addCircles(lng = ~Longtitude, lat = ~Lattitude,radius = 3,
             color = ~pal(SellerG))  %>%
  addLegend("bottomright", pal = pal, values = ~SellerG,
    title = "House distribution Top 5 sellers",
    opacity = 1
  ) %>%
  # controls
  setView(lng=center_lon, lat=center_lat, zoom=10)
```



# Variables study according with their relation with Price

+ Studied how the Price change depending on the number of house's Rooms. This is done by the next graphic, showing the average price of the houses depending on the number of rooms that it has.

```{r}
roomData = housing %>%
  group_by(Rooms) %>% 
  dplyr::summarise(AvgPricePerRoom = mean(Price)) %>%
  arrange(desc(Rooms))
  
ggplot(roomData, aes(x = Rooms,y = AvgPricePerRoom)) +
  scale_x_continuous(breaks=c(0,2,4,6,8,10,12,14,16,18,20)) +
  geom_bar(stat='identity',colour="black", fill = '#f5a742') +
  labs(x = 'Nº Rooms', y = 'Price', title = 'Average price depending of nº Rooms')
```

As it can be seen the price goes up as the number of rooms increase, until 6.

+ Car variable is studied to see if houses' average price change if they have car spot/s or not.

```{r}
carData = housing %>%
  group_by(Car) %>% 
  dplyr::summarise(AvgPriceCar = mean(Price))
  
ggplot(carData, aes(x = Car,y = AvgPriceCar, fill = Car)) +
  geom_bar(stat='identity', color='black') +
  labs(x = 'Have car spot?', y = 'Price', title = 'Average price having car spot or not')
```

It seems that the price increases a little when there are car spots, but there isn't a significant difference.

+ How the Price change depending on the Suburb where the house is located? In variable suburbData the name of the suburb and the average price of the houses in it (AvgPricePerSuburb) is stored. Also, they are sorted from higher to lower and the dollar symbol ($) is added.

```{r}
suburbData = housing %>%
             group_by(Suburb) %>% 
             dplyr::summarise(AvgPricePerSuburb = round(median(Price),0)) %>%
             arrange(desc(AvgPricePerSuburb))

suburbData$AvgPriceSuburb = scales::dollar(suburbData$AvgPricePerSuburb)
```

With the data from the most expensive Suburbs a bar plot is generated, showing the 10 more expensive and indicating their price and name.

```{r}
suburbData = suburbData[0:10,]

ggplot(suburbData, aes(x = reorder(Suburb, AvgPricePerSuburb), 
                     y = AvgPricePerSuburb)) +
  geom_bar(stat='identity',colour="white", fill = '#f5a742') +
  geom_text(aes(x = Suburb, y = 1, label = paste0("(",AvgPriceSuburb,")",sep="")),
            hjust=0, vjust=.5, size = 4, colour = 'black',
            fontface = 'bold') +
  labs(x = 'Suburb', y = 'Price', title = 'Average Price per Suburb') +
  coord_flip()
```

The rows corresponding to the top 10 most expensive suburbs are selected from the dataset and represented by their latitude and longitude in a map with leaflet library. Each dot on the map is a house and each color is a suburb. It can be seen where the most expensive properties from the city of Melbourne are situated.

```{r}
Suburbs = c(head(as.character(suburbData$Suburb),10))

SuburbsTop = housing %>% 
  filter(Suburb %in% Suburbs)

center_lon = median(SuburbsTop$Longtitude)
center_lat = median(SuburbsTop$Lattitude)

pal <- colorFactor(
  palette = 'plasma',
  domain = SuburbsTop$Suburb
)

leaflet(SuburbsTop) %>% addTiles() %>%
  addCircles(lng = ~Longtitude, lat = ~Lattitude,radius = 3,
             color = ~pal(Suburb))  %>%
  addLegend("bottomright", pal = pal, values = ~Suburb,
    title = "House distribution Top 10 Suburbs",
    opacity = 1
  ) %>%
  # controls
  setView(lng=center_lon, lat=center_lat, zoom=11)
```

+ On the next plot, change of price is shown depending on the date when the house was sold. To do this, the date is represented on the X axis (converted to Date type) and on the Y axis the property selling price.

```{r}
housingDate = housing
housingDate$Date = as.Date(housingDate$Date,format = "%d/%m/%Y")
price_trend = housingDate %>% 
  group_by(Date) %>% 
  dplyr::summarise(Average = sum(Price)/n())  
  
ggplot(price_trend, aes(x = Date, y = Average)) + 
  geom_line(color = "steelblue")
```

It seems that prices are a little bit higher the later the date is, but there is not a concrete trend identified on price variance, probably because the time period is a little over two years.

+ In the next figure it can be seen with boxplots how the price change and between what values depending on the region to which the house belongs.

```{r}
housing %>%
  ggplot(aes(x=Regionname, y = Price, fill=Regionname)) +
  geom_boxplot()+
  coord_flip()
```

There are regions whose prices are higher than others, Southern Metropolitan (represented in blue) seems to be the most expensive region.

+ The variance of price according to the type of house is as well represented with boxplots of different colors. 

```{r}
housing %>%
  ggplot(aes(x=Type, y = Price, fill=Type)) +
  geom_boxplot()
```

As it can be seen, the house Type influence clearly on the price value, being higher for type h (house) than for ype u (unit). It's higher for a house than for an apartment.

+ Same type of plot is done for the Method variable versus Price, to see it influence and if they have any relation.

```{r}
housing %>%
  ggplot(aes(x=Method, y = Price, fill=Method)) +
  geom_boxplot()
```

+ Now, variable Distance is analyzed, this variable indicate the distance of the house to the Melbourne Business District and is plotted with the Price variable using a geom point diagram.

```{r}
housing %>% 
  ggplot(data = housing, mapping = aes(x = Distance, y = Price)) +
  geom_point() +
  geom_smooth(se = FALSE)
```

There is a negative relation between Price and Distance, the shorter the distance, the higher the price of houses can be. The houses with less price value are never near the business district.

+ Lastly, it is analyzed how the variable Price is distributed using an histogram and a density curve.

```{r}
housing %>% 
  ggplot(aes(x=Price))+
  geom_histogram(aes(y=stat(density)), fill="steelblue", color = "black") + 
  geom_density(color="red", size=1.5)
```

Values are concentrated on million dollar houses, the higher the price is, less houses are with very high value.



# Price prediction Linear Regression model

According to the previous analysis, a set of the most relevant variables to the price are selected for training a linear regression model to predict Price variable.

From the initial 21 variables, 13 are selected to predict the price of the houses. The reasons to put aside the variables is:

- BuildingArea and Yearbuilt columns are deleted because of the high percentage of NAs.
- Address granularity is very high, grouping this variable will produce a lot of results.
- Suburb, CouncilArea and Date have the same granularity problem as Address, Regioname is selected as geographical variable with enough registers in the factor levels.
- Bedroom2 variable is correlated with Rooms and has some NAs so, Rooms is selected in terms of reliability.
- SellerG causes some problems when is included in the model as a factor because there are not enough registers in each level of the variable and generates a very high number of factors.

Variable fdata contains the set of variables selected.

```{r}
fdata = select(housing, Rooms , Type , Method , Distance , 
    Postcode , Bathroom , Car , Landsize , Regionname,
    Lattitude , Longtitude , Propertycount, Price)
```

Here a correlation plot between numerical variables is plotted.

As it can be observed Rooms, Bathroom, Distance, Lattitude and Longitude are the most correlated with Price variable.

Distance variable presents negative correlation with Price, higher distance from the Melbourne Business District means less price, and vice versa.

Rooms and Bathroom also have high correlation between them, when the number of rooms of the house is high, the number of bathrooms is too.

```{r}
numvars <- sapply(fdata, class) %in% c("integer","numeric")
C <- cor(fdata[,numvars])
corrplot::corrplot(C, method = "circle")
```


For training the model, Rooms column is changed to factor because there is a similar behavior in Price for the houses with 7 or more rooms, these houses are grouped when changing the variable to factor.

```{r}
fdata$Rooms <- as.factor(fdata$Rooms)
levels(fdata$Rooms) = c("1", "2", "3", "4", "5", "6", "7+", "7+", "7+", "7+")
levels(fdata$Rooms)
```

To group the registers and convert the variable to factor, same procedure is done for Bathroom variable.

```{r}
fdata$Bathroom <- as.factor(fdata$Bathroom)
levels(fdata$Bathroom) = c("0","1", "2", "3", "4", "5", "6+", "6+", "6+", "6+")
levels(fdata$Bathroom)
```

```{r}
table(fdata$Bathroom)
```


Studying Landsize variable numerous outliers that could influence negatively on the model predictions are detected.Outliers are stored in variable landsize_outliers.

```{r}
bxp_landsize <- boxplot(fdata$Landsize, plot = FALSE)
landsize_outliers <- bxp_landsize$out
```

There are outliers higher than 50000 that are eliminated from the dataset:

```{r}
fdata = fdata %>%
  filter(Landsize < 50000)
```


Finally, the linear regression model is trained using train and lm functions.

Creating training and test sets with a random distribution 80/20 of the samples.

```{r}
set.seed(150) # For replication
trainIndex <- createDataPartition(fdata$Price,   #createDataPartition creates proportional partitions
                                  p = 0.8,      #split probability for training
                                  list = FALSE, #Avoid output as a list
                                  times = 1)    #only one partition
#obtain training and validation sets
fTR <- fdata[trainIndex,]
fTS <- fdata[-trainIndex,]
```

Cross-validation is added with 10 folds.

```{r}
ctrl_tune <- trainControl(method = "cv",
                          number = 10,
                          summaryFunction = defaultSummary,    #Performance summary for comparing models in hold-out samples
                          returnResamp = "final",              #Return final information about resampling
                          savePredictions = TRUE)              #save predictions
```

Fitting the linear regression model for the training set:

```{r}
set.seed(150)
lm.fit = train(form = Price~.,
               data = fTR, 
               method = "lm",
               tuneGrid = data.frame(intercept = TRUE), 
               preProcess = c("center","scale"),
               trControl = ctrl_tune, 
               metric = "RMSE")
lm.fit #information about the resampling settings
summary(lm.fit)  #information about the model trained

#Evaluate the model with training sets and diagnosis
fTR_eval = fTR
fTR_eval$lm_pred = predict(lm.fit,  newdata = fTR)  
fTS_eval = fTS
fTS_eval$lm_pred = predict(lm.fit,  newdata = fTS)  
```

Looking at the model results, it can be observed that all the variables selected are important (little p-value), except variables MethodSA, MethodSP, Bathroom1 and Propertycount. 
A R-squared error of 0.5977 is obtained.

On the next plot, the residuals from the trained model can be observed:

```{r}
PlotModelDiagnosis(fTR, fTR$Price, fTR_eval$lm_pred,
                   together = TRUE)
```

Landsize and Price residuals stand out for making mistakes with predictions of house with higher price and terrain.

In general the model make more mistakes with the cheapest houses predicting a higher value. It also make mistakes with the most expensive houses, what means that the model do wrong in the extremes. For intermediate price houses the model has higher capability for predicting well.

Computing RMSE error for the training and test set:

```{r}
caret::RMSE(fTR_eval$lm_pred,fTR_eval$Price)
caret::RMSE(fTS_eval$lm_pred,fTS_eval$Price)
```


Training the model also with lm function to check the results obtained.

```{r}
model_l <- lm(Price ~ .,data = fTR)
summary(model_l)
```

Variables that are not relevant after the execution are MethodSA, Bathroom1, Bathroom2 and Propertycount (MethodSP is changed for Bathroom1 with respect to the previous trained model with train function). 
Same R-squared error of 0.5977 is obtained.


Now, VIF is computed for the variables of the model. Regioname has a high value, meaning that there is colineality with another variable, deleting it from the model was tested but, after checking the results, the decision is to keep the variable because is significant to the model and results in better predictions.

```{r}
vif(model_l)
```


### Diagnosis of the model

In this section some graphics are showed to check how accurate is the model with it predictions.

```{r}
plotModel = plot(model_l, which = 1, pch=19, lwd= 12)
```

In the first graphic, dots are distributed in a horizontal band of approximately similar width, but vertically are not distributed randomly as they have to be, they have a tendency of being on the top, indicating that the model tends to overestimate the price of the houses.

```{r}
plotModel = plot(model_l, which = 2, pch=19)
```

In this second QQ-plot representation it can be observed that the model does not adjust to the normal distribution on the extremes, specially on the left side.

```{r}
plotModel = plot(model_l, which = 3, pch=19)
```

Lastly, with the Scale-Location graphic the visualization of cloud of dots width seems to be more or less homogeneous, but the red line is not that horizontal because a lack of homogeneity of variances. 



# Conclusion

Throughout the document an exhaustive analysis of the variables in the dataset of houses sold in the city of Melbourne is done, providing graphs, interesting relationships between them and even including maps of the distribution of houses due to their location attending different terms.

Also, it has been studied how some of the variables have more influence than others in making the price of houses increase or decrease.

Finally, a linear regression model that provides price predictions for housing data has been trained. This model despite not having a perfect precision can offer quite successful price values for a new house in the city of Melbourne.
